{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Track Objects with RF-DETR and SORT Tracker\n",
        "\n",
        "SORT is a classic online, tracking-by-detection method that predicts object motion with a Kalman filter and matches predicted tracks to detections using the Hungarian algorithm based on Intersection over Union (IoU). The tracker uses only geometric cues from bounding boxes, without appearance features, so it runs extremely fast and scales to hundreds of frames per second on typical hardware. Detections from a strong CNN detector feed SORT, which updates each trackâ€™s state via a constant velocity motion model and prunes stale tracks. Because SORT lacks explicit re-identification or appearance cues, it can suffer identity switches and fragmented tracks under long occlusions or heavy crowding."
      ],
      "id": "fbb6eb0b476189fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup",
      "id": "253743b523d93915"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check GPU availability\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Runtime` -> `Change runtime type` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ],
      "id": "1373ae659477cce8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!nvidia-smi",
      "execution_count": null,
      "outputs": [],
      "id": "2ace994c3e9b01d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install dependencies\n",
        "\n",
        "You may see dependency conflict warnings in Google Colab. This is expected for the preinstalled Google Colab environment and does not affect functionality."
      ],
      "id": "79ab542b5b26f21f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q inference-gpu trackers==2.2.0"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ea8edfba38a212ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download example data\n",
        "\n",
        "Downloads example videos for testing. You can use these or replace them with your own images."
      ],
      "id": "470a9561a1cf7fa3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!wget -q https://storage.googleapis.com/com-roboflow-marketing/supervision/video-examples/bikes-1280x720-1.mp4\n",
        "!wget -q https://storage.googleapis.com/com-roboflow-marketing/supervision/video-examples/bikes-1280x720-2.mp4\n",
        "!wget -q https://storage.googleapis.com/com-roboflow-marketing/supervision/video-examples/skiers-1280x720-5.mp4"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "99d22b55d374567e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Track from CLI\n",
        "\n",
        "The `trackers` library provides a convenient command-line interface (CLI) for running object tracking on videos. You can quickly track objects without writing any Python code. Below is a simple example showing how to track objects using the SORT tracker.\n",
        "\n",
        "For more details on CLI options and configurations, visit the [Track from CLI documentation](https://trackers.roboflow.com/develop/learn/track/)."
      ],
      "id": "5539d0bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SOURCE_VIDEO_PATH = \"/content/bikes-1280x720-1.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/bikes-1280x720-1-result.mp4\"\n",
        "\n",
        "!trackers track \\\n",
        "    --source {SOURCE_VIDEO_PATH} \\\n",
        "    --output {TARGET_VIDEO_PATH} \\\n",
        "    --model rfdetr-medium \\\n",
        "    --tracker sort \\\n",
        "    --show-trajectories"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f6aa3ad4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TARGET_VIDEO_COMPRESSED_PATH = \"/content/bikes-1280x720-1-result-compressed.mp4\"\n",
        "\n",
        "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4e357d20"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "Video(TARGET_VIDEO_COMPRESSED_PATH, embed=True, width=1080)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c091920d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Track from Python"
      ],
      "id": "6f107f3b84e8f7e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Initiate detector and tracker",
      "id": "54d9691e3b092fb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from inference import get_model\n",
        "from trackers import SORTTracker\n",
        "\n",
        "model = get_model(\"rfdetr-medium\")\n",
        "tracker = SORTTracker()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ead319f1a7e6bc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Configure annotators",
      "id": "4390eec6cbf9921d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import supervision as sv\n",
        "\n",
        "color = sv.ColorPalette.from_hex([\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff8080\", \"#ff66b2\", \"#ff66ff\", \"#b266ff\",\n",
        "    \"#9999ff\", \"#3399ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "])\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK)\n",
        "\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK,\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=0.8)\n",
        "\n",
        "trace_annotator = sv.TraceAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK,\n",
        "    thickness=2,\n",
        "    trace_length=100)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "91387ef4403a4b2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Run detection + tracking",
      "id": "5a37e9919eb435"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CONFIDENCE_THRESHOLD = 0.2\n",
        "NMS_THRESHOLD = 0.3\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/bikes-1280x720-2.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/bikes-1280x720-2-result.mp4\"\n",
        "\n",
        "def callback(frame, i):\n",
        "    result = model.infer(frame, confidence=CONFIDENCE_THRESHOLD)[0]\n",
        "    detections = sv.Detections.from_inference(result).with_nms(threshold=NMS_THRESHOLD)\n",
        "    detections = tracker.update(detections)\n",
        "\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = box_annotator.annotate(annotated_image, detections)\n",
        "    annotated_image = trace_annotator.annotate(annotated_image, detections)\n",
        "    annotated_image = label_annotator.annotate(annotated_image, detections, detections.tracker_id)\n",
        "\n",
        "    return annotated_image\n",
        "\n",
        "tracker.reset()\n",
        "\n",
        "sv.process_video(\n",
        "    source_path=SOURCE_VIDEO_PATH,\n",
        "    target_path=TARGET_VIDEO_PATH,\n",
        "    callback=callback,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d813bdf44849d1c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Display result",
      "id": "b901c4eca751c467"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TARGET_VIDEO_COMPRESSED_PATH = \"/content/bikes-1280x720-2-result-compressed.mp4\"\n",
        "\n",
        "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "12cff76e70ec3b0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "Video(TARGET_VIDEO_COMPRESSED_PATH, embed=True, width=1080)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "65bf2d42d8354bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Camera motion compensation\n",
        "\n",
        "When tracking objects with a moving camera, trajectories can appear unstable as the camera pans or tilts. Camera motion compensation uses optical flow to estimate camera movement and stabilize trajectory visualization. This is especially useful for footage from drones, handheld cameras, or any scenario where the camera itself is in motion."
      ],
      "id": "27a25fc0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from inference import get_model\n",
        "from trackers import SORTTracker, MotionEstimator, MotionAwareTraceAnnotator\n",
        "\n",
        "PERSON_CLASS_ID = 0\n",
        "\n",
        "model = get_model(\"rfdetr-large\")\n",
        "tracker = SORTTracker(minimum_consecutive_frames=3)\n",
        "motion_estimator = MotionEstimator(\n",
        "    max_points=500,\n",
        "    min_distance=10,\n",
        "    quality_level=0.001,\n",
        "    ransac_reproj_threshold=1.0,\n",
        ")\n",
        "\n",
        "color = sv.ColorPalette.from_hex([\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff8080\", \"#ff66b2\", \"#ff66ff\", \"#b266ff\",\n",
        "    \"#9999ff\", \"#3399ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "])\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK)\n",
        "\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK,\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=0.8)\n",
        "\n",
        "motion_aware_trace_annotator = MotionAwareTraceAnnotator(\n",
        "    color=color,\n",
        "    color_lookup=sv.ColorLookup.TRACK,\n",
        "    thickness=2,\n",
        "    trace_length=100)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "efed8dac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CONFIDENCE_THRESHOLD = 0.2\n",
        "NMS_THRESHOLD = 0.3\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/skiers-1280x720-5.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/skiers-1280x720-5-result.mp4\"\n",
        "\n",
        "def callback(frame, i):\n",
        "    coord_transform = motion_estimator.update(frame)\n",
        "\n",
        "    result = model.infer(frame, confidence=CONFIDENCE_THRESHOLD)[0]\n",
        "    detections = sv.Detections.from_inference(result).with_nms(threshold=NMS_THRESHOLD)\n",
        "    detections = detections[detections.class_id == PERSON_CLASS_ID]\n",
        "    detections = tracker.update(detections)\n",
        "\n",
        "    annotated_image = frame.copy()\n",
        "    annotated_image = box_annotator.annotate(annotated_image, detections)\n",
        "    annotated_image = motion_aware_trace_annotator.annotate(\n",
        "        annotated_image, detections, coord_transform=coord_transform)\n",
        "    annotated_image = label_annotator.annotate(annotated_image, detections, detections.tracker_id)\n",
        "\n",
        "    return annotated_image\n",
        "\n",
        "tracker.reset()\n",
        "motion_estimator.reset()\n",
        "motion_aware_trace_annotator.reset()\n",
        "\n",
        "sv.process_video(\n",
        "    source_path=SOURCE_VIDEO_PATH,\n",
        "    target_path=TARGET_VIDEO_PATH,\n",
        "    callback=callback,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2f8b9735"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TARGET_VIDEO_COMPRESSED_PATH = \"/content/skiers-1280x720-5-result-compressed.mp4\"\n",
        "\n",
        "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "937b20b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "Video(TARGET_VIDEO_COMPRESSED_PATH, embed=True, width=1080)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d8726c75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You just combined SORT tracker with RF-DETR detector. Nice work!\n",
        "\n",
        "Trackers makes it easy to mix and match top-performing multi-object tracking algorithms with your favorite detection backends, including Inference, Ultralytics, and Transformers.\n",
        "\n",
        "Ready to go deeper. Explore more tracking algorithms and integrations in the trackers [Documentation](https://roboflow.github.io/trackers/) or dive into the code on [GitHub](https://github.com/roboflow/trackers).\n",
        "\n",
        "Got feedback or ideas? Open an issue on [GitHub Issues](https://github.com/roboflow/trackers/issues)."
      ],
      "id": "9186a500fd97d1f7"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}